# ğŸ­ Sentiment Analysis MLOps Pipeline

[![Python 3.12+](https://img.shields.io/badge/python-3.12%2B-blue)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/Flask-3.0%2B-green)](https://flask.palletsprojects.com/)
[![DVC](https://img.shields.io/badge/DVC-data%20versioning-blue)](https://dvc.org/)
[![MLflow](https://img.shields.io/badge/MLflow-model%20registry-red)](https://mlflow.org/)
[![AWS](https://img.shields.io/badge/AWS-deployment-orange)](https://aws.amazon.com/)
[![GitHub Actions](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-blue)](https://github.com/features/actions)

A **production-ready MLOps pipeline** for sentiment classification of YouTube comments with **automated CI/CD**, **DVC pipelines**, **MLflow tracking**, and **AWS cloud deployment**. Features multi-model training (SVM, DistilBERT), automated evaluation, model registry, and containerized serving with comprehensive testing and deployment automation.

## ğŸ¯ Key Features

- ğŸ¤– **Multi-Model Training**: SVM (baseline), SVM+SMOTE (balanced), DistilBERT (transformer)
- ğŸ”„ **DVC Pipeline**: Reproducible ML workflows with data versioning and S3 storage
- ğŸ“Š **MLflow + DagsHub**: Experiment tracking, model registry, and artifact versioning
- ğŸš€ **GitHub Actions CI/CD**: Automated testing, building, and deployment pipeline
- â˜ï¸ **AWS Architecture**: Multi-EC2 deployment with RDS PostgreSQL and load balancing
- ğŸ³ **Docker Compose**: Containerized backend (Flask) and frontend (Nginx) services
- âœ… **Comprehensive Testing**: Unit tests, smoke tests, and deployment validation
- ğŸ“ˆ **Monitoring**: Dashboard with model metrics, prediction history, and analytics

---

## ğŸ—ï¸ Complete Architecture

![MLOps Architecture](pic/diagram.png)

---

## ğŸ› ï¸ Tech Stack

### ğŸ¤– ML & Data Science
| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Embeddings** | Sentence-Transformers (all-MiniLM-L6-v2) | Text vectorization |
| **Classical ML** | scikit-learn | SVM models |
| **Class Balancing** | imbalanced-learn (SMOTE) | Handle imbalanced data |
| **Transformers** | Hugging Face Transformers | DistilBERT fine-tuning |
| **Deep Learning** | PyTorch | Backend for transformers |

### ğŸ“Š MLOps & Tracking
| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Experiment Tracking** | MLflow + DagsHub | Log metrics, params, artifacts |
| **Model Registry** | MLflow Model Registry | Version and stage models |
| **Data Versioning** | DVC + S3 | Track datasets and pipelines |
| **Pipeline Orchestration** | DVC (dvc.yaml) | Define reproducible workflows |

### ğŸŒ Serving & API
| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Web Framework** | Flask 3.0+ | REST API backend |
| **WSGI Server** | Gunicorn | Production-grade server |
| **Reverse Proxy** | Nginx | Frontend & load balancing |
| **Database** | PostgreSQL (AWS RDS) | Prediction logging & analytics |
| **Containerization** | Docker + Docker Compose | Service orchestration |

### â˜ï¸ Cloud & Infrastructure
| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Cloud Platform** | AWS | Infrastructure hosting |
| **Compute** | EC2 (t2.small/medium) | Frontend & backend servers |
| **Database** | RDS PostgreSQL 15 | Managed database service |
| **Container Registry** | Docker Hub | Image storage & distribution |
| **Networking** | VPC, Security Groups | Network isolation & security |

### ğŸ”„ CI/CD & DevOps
| Component | Technology | Purpose |
|-----------|-----------|---------|
| **CI/CD** | GitHub Actions | Automated testing & deployment |
| **Code Quality** | flake8, black, isort | Linting & formatting |
| **Testing** | pytest + pytest-cov | Unit & integration tests |
| **Secrets Management** | GitHub Secrets | Secure credential storage |

### ğŸ“¦ Key Dependencies
```bash
# ML & Data
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
imbalanced-learn>=0.11.0
sentence-transformers>=2.2.0
transformers>=4.30.0
torch>=2.0.0

# MLOps
mlflow>=2.5.0
dvc>=3.0.0
dvc[s3]

# API & Serving
flask>=3.0.0
gunicorn>=21.0.0
psycopg2-binary>=2.9.0

# DevOps
python-dotenv>=1.0.0
pyyaml>=6.0
boto3>=1.28.0
```

---

## ğŸ“ Project Structure

```
sentiment_mlops/
â”‚
â”œâ”€â”€ .github/workflows/              # GitHub Actions CI/CD
â”‚   â”œâ”€â”€ deploy.yml                 # Main deployment pipeline (10 stages)
â”‚   â””â”€â”€ deploy-prod.yml            # Production-only workflow
â”‚
â”œâ”€â”€ data/                          # Data directory (DVC tracked)
â”‚   â”œâ”€â”€ raw/                       # Original dataset
â”‚   â”‚   â”œâ”€â”€ YoutubeCommentsDataSet.csv
â”‚   â”‚   â””â”€â”€ YoutubeCommentsDataSet.csv.dvc  # DVC pointer
â”‚   â””â”€â”€ processed/                 # Preprocessed data
â”‚       â”œâ”€â”€ train_vectors.npy, train_labels.npy
â”‚       â”œâ”€â”€ test_vectors.npy, test_labels.npy
â”‚       â”œâ”€â”€ metadata.json
â”‚       â””â”€â”€ smote/                 # SMOTE-balanced training data
â”‚
â”œâ”€â”€ src/                           # Training & preprocessing scripts
â”‚   â”œâ”€â”€ pretrain.py               # Data preprocessing + optional SMOTE
â”‚   â”œâ”€â”€ train_svm_noSMOTE.py      # SVM baseline training
â”‚   â”œâ”€â”€ train_svm.py              # SVM + SMOTE training
â”‚   â”œâ”€â”€ train_bert.py             # DistilBERT fine-tuning
â”‚   â”œâ”€â”€ evaluate.py               # Model comparison & MLflow registration
â”‚   â””â”€â”€ predict.py                # Batch prediction utility
â”‚
â”œâ”€â”€ aws_serving/                   # AWS deployment files
â”‚   â”œâ”€â”€ app/                       # Backend application
â”‚   â”‚   â”œâ”€â”€ app.py                # Flask API with /predict, /health, /reload
â”‚   â”‚   â”œâ”€â”€ dashboard.py          # Dashboard routes & analytics
â”‚   â”‚   â”œâ”€â”€ database.py           # PostgreSQL RDS integration
â”‚   â”‚   â”œâ”€â”€ pull_model.py         # Download model from MLflow
â”‚   â”‚   â”œâ”€â”€ Dockerfile            # Backend container
â”‚   â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â”‚   â””â”€â”€ artifacts/            # Model artifacts (from MLflow)
â”‚   â”‚       â””â”€â”€ best_model/       # Downloaded production model
â”‚   â”œâ”€â”€ frontend/                  # Frontend Nginx proxy
â”‚   â”‚   â”œâ”€â”€ index.html            # Landing page
â”‚   â”‚   â”œâ”€â”€ nginx.conf            # Reverse proxy config
â”‚   â”‚   â””â”€â”€ Dockerfile            # Frontend container
â”‚   â”œâ”€â”€ scripts/                   # Deployment utilities
â”‚   â”‚   â”œâ”€â”€ init_rds.py           # Initialize RDS database
â”‚   â”‚   â”œâ”€â”€ inspect_run.py        # Debug MLflow runs
â”‚   â”‚   â””â”€â”€ pull_model.py         # Download from registry
â”‚   â”œâ”€â”€ docker-compose.yml         # Local development setup
â”‚   â”œâ”€â”€ docker-compose.backend.yml # Backend-only deployment
â”‚   â”œâ”€â”€ docker-compose.frontend.yml # Frontend-only deployment
â”‚   â””â”€â”€ AWS_DEPLOYMENT_GUIDE.md    # Step-by-step AWS setup
â”‚
â”œâ”€â”€ serving/                       # Legacy FastAPI server (optional)
â”‚   â”œâ”€â”€ app.py                    # FastAPI application
â”‚   â”œâ”€â”€ model_loader.py           # Load models from S3/MLflow/disk
â”‚   â”œâ”€â”€ config.py                 # Configuration management
â”‚   â”œâ”€â”€ logger.py                 # Logging utilities
â”‚   â”œâ”€â”€ requirements.txt          # Serving dependencies
â”‚   â””â”€â”€ Dockerfile                # Container for inference
â”‚
â”œâ”€â”€ models/                        # Trained model artifacts (local)
â”‚   â”œâ”€â”€ svm_sentiment.joblib      # SVM+SMOTE model
â”‚   â”œâ”€â”€ svm_scaler.joblib         # Feature scaler
â”‚   â”œâ”€â”€ svm_baseline_no_smote.joblib
â”‚   â”œâ”€â”€ distilbert_sentiment/     # DistilBERT checkpoint
â”‚   â”œâ”€â”€ svm_baseline_info.json    # Metrics for baseline
â”‚   â”œâ”€â”€ svm_model_info.json       # Metrics for SVM+SMOTE
â”‚   â”œâ”€â”€ distilbert_info.json      # Metrics for DistilBERT
â”‚   â””â”€â”€ model_comparison.csv      # Evaluation results
â”‚
â”œâ”€â”€ mlartifacts/                   # MLflow local storage
â”‚   â””â”€â”€ 1/                         # Experiment ID
â”‚       â””â”€â”€ <run_id>/              # Individual run artifacts
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks (exploratory)
â”‚   â”œâ”€â”€ preprocess.ipynb
â”‚   â”œâ”€â”€ train_svm_baseline.ipynb
â”‚   â”œâ”€â”€ train_svm.ipynb
â”‚   â””â”€â”€ train_distilbert.ipynb
â”‚
â”œâ”€â”€ tests/                         # Unit & integration tests
â”‚   â”œâ”€â”€ conftest.py               # pytest fixtures
â”‚   â”œâ”€â”€ test_app.py               # FastAPI endpoint tests
â”‚   â”œâ”€â”€ test_config.py            # Configuration tests
â”‚   â””â”€â”€ test_model_loader.py      # Model loading tests
â”‚
â”œâ”€â”€ scripts/                       # Utility scripts
â”‚   â”œâ”€â”€ pull_best_model.py        # Download from MLflow registry
â”‚   â”œâ”€â”€ promote_model.py          # Upload model to S3
â”‚   â”œâ”€â”€ deploy_hf_space.sh        # Hugging Face Space deployment
â”‚   â”œâ”€â”€ deploy.sh                 # General deployment script
â”‚   â”œâ”€â”€ setup_ec2.sh              # EC2 initial setup
â”‚   â””â”€â”€ smoke_test.sh             # Manual smoke testing
â”‚
â”œâ”€â”€ dvc.yaml                       # DVC pipeline definition (6 stages)
â”œâ”€â”€ params.yaml                    # Pipeline parameters (single source of truth)
â”œâ”€â”€ .dvc/config                    # DVC remote configuration (S3)
â”œâ”€â”€ pyproject.toml                # Project metadata & tool config
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ CI_CD_SETUP.md                # GitHub Actions setup guide
â”œâ”€â”€ DEPLOYMENT_ARCHITECTURE.md     # AWS architecture options
â”œâ”€â”€ GITHUB_SECRETS_SETUP.md        # Required secrets documentation
â””â”€â”€ README.md                      # This file
```
â””â”€â”€ README.md                      # This file
```

---

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.10+**
- **Git** & **DVC**
- **Docker** & **Docker Compose**
- **AWS Account** (for deployment)
- **DagsHub Account** (for MLflow tracking)

---

### 1ï¸âƒ£ Clone & Setup Environment

```bash
# Clone the repository
git clone https://github.com/sairam030/sentiment_mlops.git
cd sentiment_mlops

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Configure Credentials

Create a `.env` file in the project root:

```bash
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MLflow Tracking (DagsHub)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export MLFLOW_TRACKING_USERNAME="your_dagshub_username"
export MLFLOW_TRACKING_PASSWORD="your_dagshub_token"
export MLFLOW_TRACKING_URI="https://dagshub.com/your_username/mlops_sentimentAnalysis.mlflow"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AWS Credentials (for DVC & S3 model storage)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export AWS_ACCESS_KEY_ID="your_access_key"
export AWS_SECRET_ACCESS_KEY="your_secret_key"
export AWS_REGION="us-east-1"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Database (AWS RDS PostgreSQL)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export DATABASE_URL="postgresql://user:password@sentiment-db.xxxxx.us-east-1.rds.amazonaws.com:5432/sentiment_db"
export DATABASE_SSL="require"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Model Serving Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export MODEL_STAGE="production"  # or "staging"
export S3_MODEL_BUCKET="sentiment-mlops-models"
```

Load environment variables:
```bash
source .env
```

---

### 3ï¸âƒ£ Setup DVC & Pull Data

```bash
# Initialize DVC (if not already done)
dvc remote add -d myremote s3://your-bucket-name/dvc-storage
dvc remote modify myremote region us-east-1

# Pull data from remote storage
dvc pull

# Verify data
ls -lh data/raw/
```

---

### 4ï¸âƒ£ Run the DVC Pipeline

**Run the entire pipeline (all 6 stages):**
```bash
dvc repro
```

This will execute:
1. `preprocess` - Generate embeddings from raw data
2. `train_svm_baseline` - Train SVM without SMOTE
3. `preprocess_smote` - Apply SMOTE balancing
4. `train_svm_smote` - Train SVM on balanced data
5. `train_bert` - Fine-tune DistilBERT
6. `evaluate` - Compare models & register best to MLflow

**Or run individual stages:**
```bash
# Preprocess data
dvc repro preprocess

# Train specific model
dvc repro train_svm_baseline
dvc repro train_svm_smote
dvc repro train_bert

# Evaluate all models
dvc repro evaluate
```

**View pipeline DAG:**
```bash
dvc dag
```

---

### 5ï¸âƒ£ Check MLflow Experiments

```bash
# View in DagsHub (recommended)
open https://dagshub.com/sairam030/mlops_sentimentAnalysis

# Or run local MLflow UI
mlflow ui --port 5000
open http://localhost:5000
```

**Registered Models:** Navigate to "Models" tab to see:
- `sentiment-best-model`
- Model versions with aliases: `staging`, `production`
- Metrics: accuracy, F1, precision, recall

---

### 6ï¸âƒ£ Test Locally with Docker

**Build and run backend:**
```bash
cd aws_serving/app

# Pull model from MLflow first
python pull_model.py --alias production --output artifacts/

# Build Docker image
docker build -t sentiment-backend:local .

# Run container
docker run -p 5000:5000 \
  -e DATABASE_URL="${DATABASE_URL}" \
  -e DATABASE_SSL=require \
  sentiment-backend:local
```

**Test the API:**
```bash
# Health check
curl http://localhost:5000/health

# Prediction
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "This movie is amazing!"}'

# Dashboard
open http://localhost:5000/dashboard
```

---

### 7ï¸âƒ£ Deploy to AWS (CI/CD)

**Setup GitHub Secrets** (see [GITHUB_SECRETS_SETUP.md](GITHUB_SECRETS_SETUP.md)):
```
DAGSHUB_USERNAME, DAGSHUB_TOKEN
DOCKERHUB_TOKEN
TEST_FRONTEND_HOST, TEST_FRONTEND_USER, TEST_FRONTEND_SSH_KEY
TEST_BACKEND_HOST, TEST_BACKEND_USER
RDS_DATABASE_URL
PROD_FRONTEND_HOST, PROD_BACKEND_HOST, ...
```

**Trigger deployment:**
```bash
git add .
git commit -m "Deploy to AWS"
git push origin main
```

GitHub Actions will automatically:
1. Pull model from MLflow
2. Build Docker images
3. Run linting & tests
4. Push to Docker Hub
5. Deploy to TEST environment
6. Run smoke tests
7. Wait for manual approval
8. Deploy to PRODUCTION

---

## ğŸ“Š DVC Pipeline Details

The pipeline is defined in [dvc.yaml](dvc.yaml) with 6 stages orchestrated by DVC:

### Stage 1: `preprocess`
**Script:** [src/pretrain.py](src/pretrain.py)  
**Purpose:** Generate sentence embeddings and split data

```yaml
deps:
  - src/pretrain.py
  - data/raw/YoutubeCommentsDataSet.csv
params:
  - preprocess.embedding_model: all-MiniLM-L6-v2
  - preprocess.test_size: 0.2
  - preprocess.random_state: 42
outs:
  - data/processed/{train,test}_{vectors,labels}.npy
  - data/processed/metadata.json
```

**What it does:**
- Loads raw YouTube comments
- Generates 384-dim embeddings using Sentence-BERT
- Splits into 80% train, 20% test
- Saves as NumPy arrays

---

### Stage 2a: `train_svm_baseline`
**Script:** [src/train_svm_noSMOTE.py](src/train_svm_noSMOTE.py)  
**Purpose:** Baseline SVM on imbalanced data

```yaml
deps:
  - data/processed/train_vectors.npy
  - data/processed/train_labels.npy
params:
  - train.svm.kernel: rbf
  - train.svm.C: 1.0
  - train.svm.gamma: scale
outs:
  - models/svm_baseline_no_smote.joblib
  - models/svm_baseline_scaler.joblib
metrics:
  - models/svm_baseline_info.json
```

**What it does:**
- Trains SVM with RBF kernel
- No class balancing (baseline)
- Logs metrics to MLflow

---

### Stage 2b: `preprocess_smote`
**Script:** [src/pretrain.py](src/pretrain.py) `--smote`  
**Purpose:** Apply SMOTE to balance classes

```yaml
deps:
  - src/pretrain.py
params:
  - train.smote.random_state: 42
outs:
  - data/processed/smote/train_vectors.npy
  - data/processed/smote/train_labels.npy
```

**What it does:**
- Applies SMOTE oversampling to minority classes
- Balances training data distribution

---

### Stage 2c: `train_svm_smote`
**Script:** [src/train_svm.py](src/train_svm.py)  
**Purpose:** SVM on balanced data

```yaml
deps:
  - data/processed/smote/train_vectors.npy
  - data/processed/smote/train_labels.npy
outs:
  - models/svm_sentiment.joblib
  - models/svm_scaler.joblib
metrics:
  - models/svm_model_info.json
```

**What it does:**
- Trains SVM on SMOTE-balanced data
- Better performance on minority classes

---

### Stage 2d: `train_bert`
**Script:** [src/train_bert.py](src/train_bert.py)  
**Purpose:** Fine-tune DistilBERT

```yaml
deps:
  - src/train_bert.py
  - data/raw/YoutubeCommentsDataSet.csv
params:
  - train.bert.base_model: distilbert-base-uncased
  - train.bert.epochs: 3
  - train.bert.learning_rate: 2e-5
  - train.bert.batch_size: 16
  - train.bert.max_length: 128
outs:
  - models/distilbert_sentiment/
metrics:
  - models/distilbert_info.json
```

**What it does:**
- Fine-tunes DistilBERT transformer
- 3 epochs, batch size 16
- Saves in HuggingFace format

---

### Stage 3: `evaluate`
**Script:** [src/evaluate.py](src/evaluate.py)  
**Purpose:** Compare all models and register best

```yaml
deps:
  - models/svm_baseline_info.json
  - models/svm_model_info.json
  - models/distilbert_info.json
params:
  - mlflow.experiment_name: sentiment-classification
  - mlflow.registered_model_name: sentiment-best-model
outs:
  - models/model_comparison.csv
```

**What it does:**
- Loads all 3 trained models
- Evaluates on test set
- Compares: accuracy, F1, precision, recall
- Selects best model
- **Registers to MLflow Model Registry**
- Creates comparison CSV

---

## ğŸ“ˆ MLflow Integration

All training runs are tracked in MLflow with the following logged:

**Metrics Logged:**
- Accuracy, Precision, Recall, F1 (macro)
- Confusion matrix
- Training time
- Model size

**Parameters Logged:**
- SVM: kernel, C, gamma
- SMOTE: random_state
- DistilBERT: epochs, learning_rate, batch_size, max_length

**Artifacts Logged:**
- Model files (.joblib or HuggingFace format)
- Metrics JSON files
- Confusion matrix plots

**Model Registry:**
- Best model registered as `sentiment-best-model`
- Aliases: `staging`, `production`
- Versioned for rollback capability

**Access MLflow:**
```bash
# DagsHub (remote)
https://dagshub.com/sairam030/mlops_sentimentAnalysis

# Local UI
mlflow ui --port 5000
```

---

## ğŸ”„ GitHub Actions CI/CD Pipeline

The complete CI/CD pipeline is defined in [.github/workflows/deploy.yml](.github/workflows/deploy.yml)

### Pipeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GITHUB ACTIONS CI/CD - 10 STAGE PIPELINE                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Trigger: git push to main

  [1] ğŸ¯ Pull Best Model from MLflow
      â””â”€ Download production model from DagsHub
      â””â”€ Copy to aws_serving/app/artifacts/
      â””â”€ Upload as GitHub Actions artifact
      
  [2] ğŸ—ï¸ Build Docker Images
      â””â”€ Backend: Flask + Gunicorn + ML models
      â””â”€ Frontend: Nginx reverse proxy
      â””â”€ Tag as :test
      
  [3] ğŸ” Lint & Code Quality
      â””â”€ flake8 (PEP8 compliance)
      â””â”€ black (code formatting)
      â””â”€ isort (import sorting)
      
  [4] ğŸ§ª Unit Tests
      â””â”€ pytest with PostgreSQL service
      â””â”€ Coverage report generation
      â””â”€ Test: endpoints, model loading, database
      
  [5] ğŸ“¤ Push to Docker Hub (:test)
      â””â”€ Push sairam030/sentiment-backend:test
      â””â”€ Push sairam030/sentiment-frontend:test
      
  [6] ğŸš€ Deploy to Test Environment
      â””â”€ SSH to Frontend EC2 (18.61.98.223)
      â””â”€ Jump to Backend EC2 (private subnet)
      â””â”€ docker-compose up -d
      â””â”€ Inject DATABASE_URL secret
      
  [7] ğŸ’¨ Smoke Tests
      â””â”€ Health check: GET /api/health
      â””â”€ Prediction test: POST /api/predict
      â””â”€ Dashboard access: GET /dashboard
      
  [8] â¸ï¸ Manual Approval
      â””â”€ GitHub Environments protection rule
      â””â”€ Human approval required for production
      
  [9] ğŸ·ï¸ Tag Production Images
      â””â”€ Retag :test â†’ :prod
      â””â”€ Push sairam030/sentiment-backend:prod
      â””â”€ Push sairam030/sentiment-frontend:prod
      
 [10] ğŸŒ Deploy to Production
      â””â”€ SSH to Production EC2s
      â””â”€ Pull :prod images
      â””â”€ Zero-downtime deployment
      â””â”€ Validate health checks
```

### Required GitHub Secrets

See [GITHUB_SECRETS_SETUP.md](GITHUB_SECRETS_SETUP.md) for complete setup guide.

**MLflow / DagsHub:**
- `DAGSHUB_USERNAME` - Your DagsHub username
- `DAGSHUB_TOKEN` - DagsHub personal access token

**Docker Hub:**
- `DOCKERHUB_TOKEN` - Docker Hub access token

**Test Environment:**
- `TEST_FRONTEND_HOST` - Public IP of test frontend EC2
- `TEST_FRONTEND_USER` - SSH username (ubuntu)
- `TEST_FRONTEND_SSH_KEY` - Private SSH key content
- `TEST_BACKEND_HOST` - Private IP of test backend EC2
- `TEST_BACKEND_USER` - SSH username

**Production Environment:**
- `PROD_FRONTEND_HOST` - Public IP of prod frontend EC2
- `PROD_FRONTEND_USER` - SSH username
- `PROD_FRONTEND_SSH_KEY` - Private SSH key
- `PROD_BACKEND_HOST` - Private IP of prod backend EC2
- `PROD_BACKEND_USER` - SSH username

**Database:**
- `RDS_DATABASE_URL` - PostgreSQL connection string

---

## ğŸŒ API Endpoints

### `GET /`
Landing page with API information

**Response:**
```json
{
  "message": "Sentiment Analysis API",
  "endpoints": ["/predict", "/health", "/reload", "/dashboard"]
}
```

---

### `GET /health`
Health check and model status

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_type": "DistilBERT",
  "model_info": {
    "accuracy": 0.8956,
    "f1_macro": 0.8723,
    "version": "v2"
  },
  "database_connected": true
}
```

---

### `POST /predict`
Predict sentiment for text input

**Request:**
```json
{
  "text": "This movie was absolutely amazing! I loved every minute of it."
}
```

**Response:**
```json
{
  "text": "This movie was absolutely amazing! I loved every minute of it.",
  "prediction": "POSITIVE",
  "confidence": 0.9876,
  "all_scores": {
    "POSITIVE": 0.9876,
    "NEUTRAL": 0.0098,
    "NEGATIVE": 0.0026
  },
  "model_type": "DistilBERT",
  "latency_ms": 45.23
}
```

---

### `POST /reload`
Hot-reload model without restarting server

**Request:**
```json
{
  "alias": "production"
}
```

**Response:**
```json
{
  "status": "success",
  "message": "Model reloaded successfully",
  "model_type": "DistilBERT",
  "version": "v3"
}
```

---

### `GET /dashboard`
Interactive dashboard with:
- Model comparison metrics
- Prediction history (last 100 predictions)
- Sentiment distribution chart
- System health indicators

**Access:** `http://18.61.98.223/dashboard`

---

## ğŸ§ª Testing

### Run Tests Locally

```bash
# Install test dependencies
pip install pytest pytest-cov pytest-mock

# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=serving --cov-report=html

# Open coverage report
open htmlcov/index.html
```

### Test Coverage

**Unit Tests:**
- âœ… API endpoint testing ([tests/test_app.py](tests/test_app.py))
- âœ… Configuration validation ([tests/test_config.py](tests/test_config.py))
- âœ… Model loading from disk/S3/MLflow ([tests/test_model_loader.py](tests/test_model_loader.py))

**Integration Tests:**
- âœ… PostgreSQL database connection
- âœ… MLflow artifact download
- âœ… End-to-end prediction flow

**Smoke Tests (CI/CD):**
- âœ… Health endpoint validation
- âœ… Sample prediction verification
- âœ… Dashboard accessibility

---

## ğŸš¢ Deployment Options

### Option 1: AWS Multi-EC2 (Current)

**Architecture:** Separate EC2s for frontend and backend per environment

**Advantages:**
- âœ… Independent scaling
- âœ… Better isolation
- âœ… Production-grade setup

**Setup Guide:** See [DEPLOYMENT_ARCHITECTURE.md](DEPLOYMENT_ARCHITECTURE.md)

---

### Option 2: Docker Compose (Local/Single Server)

```bash
cd aws_serving

# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

**Services Started:**
- Backend: http://localhost:5000
- Frontend: http://localhost:80
- Dashboard: http://localhost:80/dashboard

---

### Option 3: Hugging Face Spaces

```bash
# Deploy to HF Spaces
bash scripts/deploy_hf_space.sh

# Or manually
cd hf_space
huggingface-cli login
huggingface-cli repo create sentiment-analysis --type space --space_sdk docker
git push hf main
```

---

## ğŸ“ Configuration

All pipeline parameters are centralized in [params.yaml](params.yaml):

```yaml
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Paths Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
paths:
  raw_data: data/raw/YoutubeCommentsDataSet.csv
  processed_dir: data/processed/
  models_dir: models/

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Preprocessing Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
preprocess:
  embedding_model: all-MiniLM-L6-v2      # Sentence-BERT model
  test_size: 0.2                         # 80/20 train/test split
  random_state: 42                       # Reproducibility

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Training Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
train:
  # SVM Hyperparameters
  svm:
    kernel: rbf                          # RBF kernel
    C: 1.0                               # Regularization
    gamma: scale                         # Kernel coefficient
    random_state: 42
  
  # SMOTE Configuration
  smote:
    random_state: 42                     # For reproducibility
  
  # DistilBERT Configuration
  bert:
    base_model: distilbert-base-uncased  # HuggingFace model
    epochs: 3                            # Training epochs
    learning_rate: 2e-5                  # AdamW learning rate
    batch_size: 16                       # Batch size
    max_length: 128                      # Max token length
    weight_decay: 0.01                   # L2 regularization
    warmup_ratio: 0.1                    # LR warmup

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MLflow Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mlflow:
  experiment_name: sentiment-classification
  tracking_uri: https://dagshub.com/sairam030/mlops_sentimentAnalysis.mlflow
  registered_model_name: sentiment-best-model
```

**To modify parameters:**
1. Edit `params.yaml`
2. Run `dvc repro` to re-execute affected stages
3. DVC automatically tracks parameter changes

---

## ğŸ”§ Advanced Usage

### Train with GPU

```bash
# Check GPU availability
nvidia-smi

# Set CUDA device
export CUDA_VISIBLE_DEVICES=0

# Run DistilBERT training
dvc repro train_bert
```

---

### Skip Certain Stages

```bash
# Train only SVM, skip BERT
dvc repro --single-item train_svm_smote

# Run until specific stage
dvc repro train_svm_baseline
```

---

### View Metrics

```bash
# Show all metrics
dvc metrics show

# Compare metrics across branches
dvc metrics diff main experiment-branch
```

---

### Push/Pull DVC Data

```bash
# Push data to remote (S3)
dvc push

# Pull data from remote
dvc pull

# Check remote status
dvc status --remote
```

---

### Debug Pipeline

```bash
# Dry run (show what will execute)
dvc repro --dry

# Force re-run specific stage
dvc repro -f train_bert

# Show pipeline dependency graph
dvc dag --md
```

---

### Manual Model Promotion

```bash
# Download from MLflow
python scripts/pull_best_model.py --alias production --output artifacts/

# Promote to S3 (optional)
python scripts/promote_model.py --latest --alias production
```

---

### Database Management

```bash
# Initialize RDS database
cd aws_serving/scripts
python init_rds.py

# Inspect predictions
python -c "from database import get_all_predictions; print(get_all_predictions(limit=10))"
```

---

## ğŸ“š Dataset Information

**Source:** YouTube Comments Dataset  
**Size:** ~15,000 comments  
**Labels:** 
- ğŸŸ¢ **Positive** (1)
- ğŸŸ¡ **Neutral** (0)  
- ğŸ”´ **Negative** (-1)

**Location:** `data/raw/YoutubeCommentsDataSet.csv`

**Sample Data:**
```csv
text,label
"This video is amazing!",1
"Not sure what to think about this",0
"Terrible content, waste of time",-1
```

**Class Distribution:**
- Imbalanced dataset (use SMOTE to balance)
- Majority class: Positive
- Minority class: Negative

---

## ğŸ”’ Security Best Practices

**Secrets Management:**
- âœ… Never commit `.env` files
- âœ… Use GitHub Secrets for CI/CD
- âœ… Rotate credentials regularly
- âœ… Use IAM roles for AWS access

**Network Security:**
- âœ… Backend in private subnet
- âœ… RDS in private subnet
- âœ… Security groups restrict access
- âœ… SSL/TLS for database connections

**Docker Security:**
- âœ… Use non-root users in containers
- âœ… Scan images for vulnerabilities
- âœ… Keep base images updated
- âœ… Minimize attack surface

---

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Make changes and test**
   ```bash
   pytest tests/ -v
   flake8 src/ serving/
   black src/ serving/ tests/
   ```
4. **Commit changes**
   ```bash
   git commit -m "Add amazing feature"
   ```
5. **Push to branch**
   ```bash
   git push origin feature/amazing-feature
   ```
6. **Open a Pull Request**

**Code Quality Checks:**
- Linting: `flake8`
- Formatting: `black`
- Import sorting: `isort`
- Type checking: `mypy` (optional)

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **DagsHub** for MLflow hosting and version control
- **Hugging Face** for transformer models and datasets
- **Sentence-Transformers** for embedding generation
- **AWS** for cloud infrastructure
- **GitHub Actions** for CI/CD automation

---

## ğŸ‘¤ Author

**Sairam**
- GitHub: [@sairam030](https://github.com/sairam030)
- DagsHub: [@sairam030](https://dagshub.com/sairam030)
- Project: [sentiment_mlops](https://github.com/sairam030/sentiment_mlops)

---

## ğŸ”— Related Documentation

- [CI/CD Setup Guide](CI_CD_SETUP.md) - Complete GitHub Actions setup
- [Deployment Architecture](DEPLOYMENT_ARCHITECTURE.md) - AWS infrastructure options
- [GitHub Secrets Setup](GITHUB_SECRETS_SETUP.md) - Required secrets configuration
- [AWS Deployment Guide](aws_serving/AWS_DEPLOYMENT_GUIDE.md) - Step-by-step AWS deployment

---

## ğŸ“ Support

For issues, questions, or contributions:
- ğŸ› [Open an issue](https://github.com/sairam030/sentiment_mlops/issues)
- ğŸ’¬ [Start a discussion](https://github.com/sairam030/sentiment_mlops/discussions)
- ğŸ“§ Contact via GitHub profile

---

## ğŸ¯ Project Status

- âœ… DVC Pipeline: **Production Ready**
- âœ… MLflow Tracking: **Active**
- âœ… CI/CD Pipeline: **Operational**
- âœ… AWS Deployment: **Running**
- âœ… Test Coverage: **>80%**
- ğŸš§ Monitoring Dashboard: **In Progress**

---

**Last Updated:** February 2026  
**Version:** 2.0.0  
**License:** MIT



