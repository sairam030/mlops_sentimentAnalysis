{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "762ccf7f",
   "metadata": {},
   "source": [
    "# Approach 0: SVM Baseline (No SMOTE)\n",
    "\n",
    "Train SVM on embeddings + VADER features **without** SMOTE balancing.\n",
    "This is the simplest baseline — shows how the model performs on the natural (imbalanced) class distribution.\n",
    "\n",
    "**Compare with:**\n",
    "- Approach 1: SVM + SMOTE (`train_svm.ipynb`)\n",
    "- Approach 2: DistilBERT fine-tuned (`train_distilbert.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07ee8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ram/sentiment_mlops/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Paths\n",
    "RAW_DATA_PATH = '/home/ram/sentiment_mlops/data/raw/YoutubeCommentsDataSet.csv'\n",
    "MODEL_PATH = '/home/ram/sentiment_mlops/models/'\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "EMBEDDING_MODEL = 'all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60b4bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 18408\n",
      "\n",
      "Class distribution (IMBALANCED — no SMOTE):\n",
      "Sentiment\n",
      "positive    11432\n",
      "neutral      4638\n",
      "negative     2338\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance ratio: 4.9x\n"
     ]
    }
   ],
   "source": [
    "## 1. Load & Clean Data\n",
    "df = pd.read_csv(RAW_DATA_PATH)\n",
    "df['Comment'] = df['Comment'].fillna('').astype(str)\n",
    "\n",
    "# Keep raw text for VADER\n",
    "df['raw_comment'] = df['Comment']\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(clean_text)\n",
    "df = df[df['Sentiment'].isin(['positive', 'negative', 'neutral'])]\n",
    "\n",
    "label_map = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "df['label'] = df['Sentiment'].map(label_map)\n",
    "\n",
    "print(f'Total samples: {len(df)}')\n",
    "print(f'\\nClass distribution (IMBALANCED — no SMOTE):')\n",
    "print(df['Sentiment'].value_counts())\n",
    "print(f'\\nImbalance ratio: {df[\"Sentiment\"].value_counts().max() / df[\"Sentiment\"].value_counts().min():.1f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92aa995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] Generating sentence embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 275.32it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Batches: 100%|██████████| 576/576 [00:11<00:00, 48.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Extracting VADER features...\n",
      "\n",
      "Feature matrix: (18408, 388)\n"
     ]
    }
   ],
   "source": [
    "## 2. Generate Features (Embeddings + VADER)\n",
    "print('[1/2] Generating sentence embeddings...')\n",
    "st_model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "embeddings = st_model.encode(df['Comment'].tolist(), show_progress_bar=True)\n",
    "\n",
    "print('[2/2] Extracting VADER features...')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vader_features = []\n",
    "for text in df['raw_comment']:\n",
    "    s = analyzer.polarity_scores(text)\n",
    "    vader_features.append([s['compound'], s['pos'], s['neg'], s['neu']])\n",
    "vader_features = np.array(vader_features)\n",
    "\n",
    "# Combine: 384-d embeddings + 4-d VADER = 388-d\n",
    "scaler_vader = StandardScaler()\n",
    "vader_scaled = scaler_vader.fit_transform(vader_features)\n",
    "X = np.hstack([embeddings, vader_scaled])\n",
    "y = df['label'].values\n",
    "\n",
    "print(f'\\nFeature matrix: {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7acee29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (14726, 388), Test: (3682, 388)\n",
      "\n",
      "Train class distribution (imbalanced):\n",
      "  positive  :  9146 (62.1%)\n",
      "  neutral   :  3710 (25.2%)\n",
      "  negative  :  1870 (12.7%)\n"
     ]
    }
   ],
   "source": [
    "## 3. Train/Test Split (NO SMOTE)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')\n",
    "print(f'\\nTrain class distribution (imbalanced):')\n",
    "for label_id in sorted(inv_label_map.keys()):\n",
    "    count = (y_train == label_id).sum()\n",
    "    print(f'  {inv_label_map[label_id]:10s}: {count:5d} ({count/len(y_train)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587d0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM (no SMOTE — imbalanced data)...\n",
      "[LibSVM]....*..*\n",
      "optimization finished, #iter = 6358\n",
      "obj = -2561.750131, rho = -0.725933\n",
      "nSV = 4784, nBSV = 2588\n",
      "Total nSV = 4784\n",
      "....*..*\n",
      "optimization finished, #iter = 6351\n",
      "obj = -2532.083087, rho = -0.777449\n",
      "nSV = 4726, nBSV = 2515\n",
      "Total nSV = 4726\n",
      "....*..*\n",
      "optimization finished, #iter = 6205\n",
      "obj = -2502.074388, rho = -0.677651\n",
      "nSV = 4699, nBSV = 2490\n",
      "Total nSV = 4699\n",
      "....*..*\n",
      "optimization finished, #iter = 6457\n",
      "obj = -2571.298468, rho = -0.659474\n",
      "nSV = 4808, nBSV = 2554\n",
      "Total nSV = 4808\n",
      "....*..*\n",
      "optimization finished, #iter = 6414\n",
      "obj = -2550.319595, rho = -0.668317\n",
      "nSV = 4771, nBSV = 2536\n",
      "Total nSV = 4771\n",
      ".....*..*\n",
      "optimization finished, #iter = 7821\n",
      "obj = -3145.365730, rho = 0.725721\n",
      "nSV = 5780, nBSV = 3138\n"
     ]
    }
   ],
   "source": [
    "## 4. Scale & Train SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Training SVM (no SMOTE — imbalanced data)...')\n",
    "svm_baseline = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale',\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "svm_baseline.fit(X_train_scaled, y_train)\n",
    "print('\\nTraining complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Evaluate on Test Set\n",
    "y_pred = svm_baseline.predict(X_test_scaled)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'\\n{\"=\"*50}')\n",
    "print(f'  TEST ACCURACY (No SMOTE): {acc:.4f} ({acc*100:.1f}%)')\n",
    "print(f'{\"=\"*50}\\n')\n",
    "\n",
    "target_names = [inv_label_map[i] for i in sorted(inv_label_map.keys())]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d441b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=target_names, yticklabels=target_names, ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix — SVM Baseline (No SMOTE)')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Oranges',\n",
    "            xticklabels=target_names, yticklabels=target_names, ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix — Normalized')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Highlight per-class recall (critical for imbalanced data)\n",
    "print('Per-class recall (sensitivity):')\n",
    "for i, name in enumerate(target_names):\n",
    "    recall = cm_norm[i, i]\n",
    "    flag = ' ⚠️ LOW' if recall < 0.5 else ''\n",
    "    print(f'  {name:10s}: {recall:.1%}{flag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26969a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Confidence Distribution\n",
    "y_proba = svm_baseline.predict_proba(X_test_scaled)\n",
    "y_confidence = y_proba.max(axis=1)\n",
    "correct_mask = y_pred == y_test\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(y_confidence, bins=30, edgecolor='black', alpha=0.7, color='#e67e22')\n",
    "axes[0].set_title('Prediction Confidence — SVM Baseline')\n",
    "axes[0].set_xlabel('Confidence (max probability)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].axvline(x=0.5, color='red', linestyle='--', label='Random guess')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(y_confidence[correct_mask], bins=30, alpha=0.7, label='Correct', color='green')\n",
    "axes[1].hist(y_confidence[~correct_mask], bins=30, alpha=0.7, label='Wrong', color='red')\n",
    "axes[1].set_title('Confidence: Correct vs Wrong')\n",
    "axes[1].set_xlabel('Confidence')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean confidence (correct): {y_confidence[correct_mask].mean():.3f}')\n",
    "print(f'Mean confidence (wrong):   {y_confidence[~correct_mask].mean():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c314829",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Save Baseline Model\n",
    "joblib.dump(svm_baseline, os.path.join(MODEL_PATH, 'svm_baseline_no_smote.joblib'))\n",
    "joblib.dump(scaler, os.path.join(MODEL_PATH, 'svm_baseline_scaler.joblib'))\n",
    "\n",
    "model_info = {\n",
    "    'model': 'SVM (RBF) — No SMOTE Baseline',\n",
    "    'accuracy': float(acc),\n",
    "    'features': 'sentence_embeddings(384) + vader_scaled(4)',\n",
    "    'feature_dim': int(X_train.shape[1]),\n",
    "    'train_samples': int(X_train.shape[0]),\n",
    "    'test_samples': int(X_test.shape[0]),\n",
    "    'smote': False,\n",
    "    'label_map': label_map\n",
    "}\n",
    "with open(os.path.join(MODEL_PATH, 'svm_baseline_info.json'), 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print('Saved:')\n",
    "print(f'  Model:  {MODEL_PATH}svm_baseline_no_smote.joblib')\n",
    "print(f'  Scaler: {MODEL_PATH}svm_baseline_scaler.joblib')\n",
    "print(f'  Info:   {MODEL_PATH}svm_baseline_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Compare All Approaches (so far)\n",
    "print('\\n' + '='*65)\n",
    "print('  MODEL COMPARISON')\n",
    "print('='*65)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Approach 0 — this notebook\n",
    "rows.append({\n",
    "    'Approach': '0: SVM (No SMOTE)',\n",
    "    'Accuracy (%)': round(acc * 100, 1),\n",
    "    'SMOTE': 'No',\n",
    "    'Train Samples': X_train.shape[0]\n",
    "})\n",
    "\n",
    "# Approach 1 — SVM + SMOTE\n",
    "svm_smote_path = os.path.join(MODEL_PATH, 'svm_model_info.json')\n",
    "if os.path.exists(svm_smote_path):\n",
    "    with open(svm_smote_path) as f:\n",
    "        svm_info = json.load(f)\n",
    "    rows.append({\n",
    "        'Approach': '1: SVM + SMOTE',\n",
    "        'Accuracy (%)': round(svm_info['accuracy'] * 100, 1),\n",
    "        'SMOTE': 'Yes',\n",
    "        'Train Samples': svm_info['train_samples']\n",
    "    })\n",
    "\n",
    "# Approach 2 — DistilBERT\n",
    "bert_path = os.path.join(MODEL_PATH, 'distilbert_sentiment/model_info.json')\n",
    "if os.path.exists(bert_path):\n",
    "    with open(bert_path) as f:\n",
    "        bert_info = json.load(f)\n",
    "    rows.append({\n",
    "        'Approach': '2: DistilBERT',\n",
    "        'Accuracy (%)': round(bert_info['accuracy'] * 100, 1),\n",
    "        'SMOTE': 'N/A',\n",
    "        'Train Samples': bert_info['train_samples']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(rows)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Bar chart\n",
    "if len(rows) > 1:\n",
    "    colors = ['#e67e22', '#3498db', '#9b59b6'][:len(rows)]\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    bars = ax.bar(comparison_df['Approach'], comparison_df['Accuracy (%)'], color=colors, width=0.5)\n",
    "    for bar, val in zip(bars, comparison_df['Accuracy (%)']):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
    "                f'{val}%', ha='center', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Test Accuracy (%)')\n",
    "    ax.set_title('Sentiment Classification — All Approaches')\n",
    "    ax.set_ylim(0, 100)\n",
    "    plt.xticks(rotation=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10. Quick Test — Predict on Sample Comments\n",
    "def predict_sentiment(texts):\n",
    "    cleaned = [clean_text(t) for t in texts]\n",
    "    embs = st_model.encode(cleaned)\n",
    "    vader = []\n",
    "    for t in texts:\n",
    "        s = analyzer.polarity_scores(t)\n",
    "        vader.append([s['compound'], s['pos'], s['neg'], s['neu']])\n",
    "    vader = scaler_vader.transform(np.array(vader))\n",
    "    features = np.hstack([embs, vader])\n",
    "    features_scaled = scaler.transform(features)\n",
    "    preds = svm_baseline.predict(features_scaled)\n",
    "    proba = svm_baseline.predict_proba(features_scaled)\n",
    "    results = []\n",
    "    for i, text in enumerate(texts):\n",
    "        results.append({\n",
    "            'text': text[:80],\n",
    "            'prediction': inv_label_map[preds[i]],\n",
    "            'confidence': f\"{proba[i].max():.1%}\"\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "test_comments = [\n",
    "    \"This video is absolutely amazing! Best tutorial ever!\",\n",
    "    \"Terrible content, waste of my time.\",\n",
    "    \"The video is 10 minutes long.\",\n",
    "    \"I love how you explained the concept so clearly, subscribed!\",\n",
    "    \"Boring and poorly made, dislike.\",\n",
    "    \"Can someone tell me the timestamp for the second part?\"\n",
    "]\n",
    "\n",
    "predict_sentiment(test_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab98b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
